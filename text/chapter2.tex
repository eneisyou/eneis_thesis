\chapter{基礎概念}

本章では、本研究が提案するシステム ARShow の設計および実装の基盤となる概念と技術的背景について述べる。まず、展示の主体であるキュレーターの役割の変化と、デジタル展示における課題を整理する。次に、その解決手段としての AR （拡張現実）技術の定義と分類について概説する。続いて、実装環境である Unity および Meta XR SDK の特性を述べ、本研究の核心技術である HybridCLR を用いたホットアップデート機構、およびシステム全体の運用を支える通信アーキテクチャについて詳述する。

\section{キュレーションの変遷と定義}
\subsection{博物館における伝統的役割}

伝統的にキュレーター（学芸員）は、博物館法や ICOM （国際博物館会議）の規定に基づき、資料の収集、保存、調査研究、および展示企画を専門的に担う職種として定義されてきた。博物館という制度的枠組みの中で、歴史的かつ芸術的価値を持つ資料を体系化し、教育的配慮のもとで公衆へ提示することがその主たる役割であった。

\subsection{インディペンデントキュレーターの台頭}

近年、特定の博物館組織に所属せず、独自の文脈とテーマ設定によって展覧会を構成するインディペンデントキュレーターの活動が顕著となっている。Obrist らが指摘するように、現代のキュレーターの役割は単なる管理や保存から、新たな意味を創出するプロデューサーとしての側面を強めている。彼らの活動領域は物理空間にとどまらず、デジタル技術を用いた空間表現にも及んでいる。

\subsection{本研究における定義と課題}

AR を用いた空間芸術展示において、キュレーターの役割は鑑賞体験全体の設計者へと拡張されている。しかし、高度なデジタル技術の導入は、鑑賞者に対するデバイス操作説明やアプリケーション導入支援といった、展示の本質とは異なるコミュニケーションコストの増大を招いている。本研究では、Unity における技術的背景を持つだけ、デジタル空間で展示構成を行い、鑑賞者へ体験を提供する主体としてキュレーターを定義する。

\section{拡張現実技術}
\subsection{拡張現実の定義}

拡張現実（Augmented Reality: AR）とは、実世界の情報にコンピュータ生成情報をリアルタイムに重畳し、人間の知覚を拡張する技術である。Azuma による定義では、以下の 3 要素を満たすものとされる。

1、現実と仮想の結合（Combines real and virtual）

2、リアルタイムなインタラクション（Interactive in real time）

3、3 次元的な位置合わせ（Registered in 3D）


\subsection{ロケーションベースAR}

GPS （全地球測位システム）や磁気センサ、加速度センサ等の位置情報を利用し、特定の地理的座標にデジタルコンテンツを配置する手法である。広域な屋外展示には適しているが、屋内における位置特定精度や、高さ方向の正確な整合（レジストレーション）に課題が残る場合が多く、精密な芸術作品の配置には不向きである。

\subsection{マーカ型ビジョンベース AR}

特定の画像（マーカ）をカメラで認識し、その特徴量に基づいてデジタルコンテンツの表示位置や傾きを決定する手法である。本研究では、AR コンテンツの識別子（ID）と空間的な配置基準点（空間アンカー）の両方の機能を併せ持つ QR コードをマーカとして採用する。これにより、鑑賞者は意図した作品を正確な位置で呼び出すことが可能となる。

\subsection{マーカレス型ビジョンベース AR}

特定のマーカを必要とせず、SLAM （Simultaneous Localization and Mapping）技術等を用いて周囲の環境形状をリアルタイムに解析し認識する手法である。本研究で使用する HMD （ヘッドマウンドディスプレイ）の Meta Quest 3 等最新デバイスでは、深度センサとカメラを用いた高度な空間認識が可能であり、壁面や床面を物理的な制約としてデジタルコンテンツに反映させることができる。しかし、この方式では計算量が多くて単なる HMD を用いてのリアルタイム性および安定性はマーカ型より劣っている。

\section{Unity 開発プラットフォーム}
\subsection{Unity (ユニティ)}

Unity は Unity Technologies 社が提供するリアルタイム 3D 開発プラットフォームであり、XR コンテンツ開発におけるデファクトスタンダードである。物理演算、レンダリング、オーディオ処理などの機能が統合されており、C\# スクリプトによる柔軟なロジック記述が可能である。

\subsection{Prefab (プレハブ)}

Prefab は GameObject、コンポーネント(C\# スクリプト)、およびプロパティ設定を一つのアセットとしてテンプレート化する機能である。これにより、展示作品を構成する複雑なオブジェクト群を一つの単位として管理し、動的に生成または破棄することが容易となる。

\subsection{AssetBundle (アセットバンドル)}

AssetBundle は Unity のアセットを実行時に外部からロード可能な形式でアーカイブする機能である。本研究では、1つの展示作品を1つの AssetBundle に対応させる設計を採用している。これにより、アプリケーション本体を更新することなく、サーバ上のアーカイブファイルを差し替えるだけでコンテンツを追加や更新することが可能となる。

\subsection{MonoBehavior}



\subsection{UUID}



\subsection{Assembly}



\subsection{Metaファイル}



\subsection{制約}

標準的な Unity の仕様において、AssetBundle はテクスチャやモデルデータなどの非コードアセットの更新には適しているが、ロジック（C\# スクリプト）の更新を含めることはできない。これは、インタラクションの挙動を変更したい場合にアプリ全体の再ビルドと再配布が必要となることを意味し、展示運営上の大きなボトルネックとなっていた。

\section{Meta XR All-in-One SDK}
\subsection{パススルー機能}

Meta XR SDK は、Meta Quest シリーズのハードウェア機能を Unity 上で制御するための開発キットである。特に本研究では、外部カメラで取得した現実映像に CG を合成するカラーパススルー機能を活用し、現実空間と展示コンテンツがシームレスに融合した AR （拡張現実）体験を構築する。

\subsection{Meta XR Interaction SDK}

Meta XR Interaction SDK は Meta XR All-in-One SDK に内臓され、ハンドトラッキングやコントローラ操作を抽象化し、標準的なインタラクションを提供するライブラリである。これにより、鑑賞者は「掴む」「指差す」といった直感的な身体動作で AR コンテンツを操作することが可能となり、没入感を阻害しない操作体系が実現される。

\subsection{Meta XR Voice SDK}

Meta XR Voice SDK は Meta XR All-in-One SDK に統合された音声認識モジュールであり、アプリケーションに対して音声入力インターフェースを提供するライブラリである。本 SDK は、マイクから取得した音声データの正規化やストリーミング処理を担い、後述する自然言語処理プラットフォーム Wit.AI との通信を仲介する役割を果たす。これにより、開発者は低レイヤーの音声信号処理を意識することなく、HMD 装着時のハンズフリー操作や、コントローラでは表現しきれない直感的な音声コマンド（作品解説の呼び出し、シーン切り替え等）を実装することが可能となる。

\subsection{Wit.AI}

Wit.AI は Meta 社が提供する自然言語処理（Natural Language Processing: NLP）プラットフォームであり、ユーザーの非構造化データ（音声やテキスト）を、コンピュータが処理可能な構造化データへと変換するクラウドサービスである。本研究において、Wit.AI は鑑賞者の発話意図を解析し、具体的な操作命令へと変換する核心的なエンジンとして機能する。Wit.AI の処理プロセスは主に以下の要素によって構成される。

1. Intents (インテント)

インテントは、ユーザーの発話が「何をしようとしているのか」という意図を定義したものである。例えば、「解説を再生して」や「次の作品へ移動」といった発話に対し、それぞれ PlayDescription や MoveToNext といった識別子を割り当てる。システムは返却されたインテント識別子に基づき、実行すべき C\# メソッドを決定する。

2. Entities (エンティティ)

エンティティは、発話に含まれる具体的なパラメータや変数を抽出するための定義である。例えば、「作品Aを見せて」という発話において、「見せて」はインテントであるが、「作品A」は操作対象を特定する重要な情報である。Wit.AI は事前に学習させたキーワードや文脈に基づき、このような固有名称や数値を抽出し、インテントに付随する引数としてアプリケーションへ返却する。

3. Traits (トレイト)

トレイトは、発話全体の意味合いやニュアンスを分類する機能である。肯定または否定の判定や感情分析などに用いられる。例えば、確認ダイアログに対する「はい」「いいえ」の応答判定などに利用され、より自然な対話フローの構築に寄与する。

これらの機能により、Wit.AI は単なる音声のテキスト化（Speech-to-Text）にとどまらず、文脈理解（Natural Language Understanding: NLU）を伴う高度なインタラクションを実現する。開発者は Web コンソール上でこれらの定義と学習を行うだけで、複雑な機械学習アルゴリズムを自作することなく、高精度な音声対話システムを構築可能である。

\section{HybridCLR とホットアップデート}
\subsection{IL2CPP の技術的課題}

Unity のモバイルおよび XR 向けビルド（Intermediate Language to C++: IL2CPP）では、C\# コードが C++ へ事前コンパイル（Ahead-Of-Time: AOT）される。この仕組みにより高い実行性能が得られる反面、実行中に新たな C\# コードを動的に読み込んで実行することは構造上不可能であった。

\subsection{HybridCLR の導入}

HybridCLR は IL2CPP 環境下において、AOT 実行とインタープリタ実行を混在させることで C\# の完全なホットアップデートを実現する革新的なフレームワークである。これにより、コンパイル済みのバイナリ上で、サーバからダウンロードした DLL （アセンブリ）内のメタデータと命令を解釈かつ実行することが可能となる。

\subsection{AddComponent ベース更新}

実行時にロードしたアセンブリ内のクラス情報を利用し、AddComponentメソッドを通じて既存のGameObjectに新たなコンポーネント（ロジック）を動的に付与する手法である。これにより、アプリリリース時には存在しなかった全く新しい機能や振る舞いを作品に追加できる。本研究ではこの技術を採用することで、キュレーターが作成した複雑なインタラクションロジックを、AssetBundleの一部として鑑賞者アプリへ即座に反映させることを可能にしている。

\subsection{Asset ベース更新}

Prefab 内にシリアライズされたスクリプト参照を、実行時にロードした最新のスクリプトコードへと自動的に解決（リマップ）する手法である。注意すべきなのは、スクリプトをデシリアライズする際に同一 Unity プロジェクトで生成したメタファイルの解析する必要があるため、異なるプロジェクトからの Prefab が中身のスクリプト自動的にリマップ出来ないとなる。

\section{静的なサーバ}
\subsection{xxx}



\section{クライアントとサーバ型の配信アーキテクチャ}
\subsection{システム構成}

提案するシステムは、コンテンツを一元管理する静的ファイルサーバ、それを制作かつアップロードするキュレーター端ツール（ARShowNode）、および鑑賞者が利用するクライアントアプリ（ARShow）の三要素から成るクライアントサーバモデルを採用している。

\subsection{コンテンツの分離とオンデマンド配信}

展示作品の実体である AssetBundle は、アプリケーション内部には保持されず、外部サーバに配置される。クライアントアプリは QR コードの読み取りをトリガーとして、必要なデータのみをオンデマンドで取得し展開する。

\subsection{運用上の利点}

このアーキテクチャにより、鑑賞者のデバイスストレージを圧迫することなく、無限に作品を追加することが可能となる。また、展示内容の更新はサーバ側のアーカイブファイル差し替えのみで完結するため、上文で述べた「更新プロセスの困難さ」および「コミュニケーションコスト」の課題を根本から解決する基盤となる。
