\chapter{提案システム}

\section{設計思想}

本節では、本研究で提案したAR展示システムの設計思想について述べる。

本システムは、AR （拡張現実）を用いた芸術展示において、キュレーター（制作者）と鑑賞者（閲覧者）の間に存在するコミュニケーションコストの削減、および展示コンテンツの持続可能な運用を解決することを主たる目的として設計された。従来のデジタル芸術展示、特にアプリベースの AR 展示においては、策展者が作品を公開するためにアプリケーションそのものを配布する必要があり、更新のたびに再配布や再インストールが求められるという課題があった。また、展示会終了とともにアプリのサポートが終了し、作品の鑑賞が不可能になるケースも散見される。さらに、鑑賞者にとっても、展示ごとに異なる操作方法や導入手順を学習する必要があり、これが鑑賞体験への障壁となっていた。

これらの課題に対し、本システムはキュレーターと鑑賞者を媒介するプラットフォームとしての役割を果たす。本システムの設計思想を図\ref{fig:tobita_config}に示す。具体的には、Unity の AssetBundle 機能と HybridCLR によるホットアップデート技術を組み合わせることで、アプリケーション本体を更新することなく、展示コンテンツ（ロジックを含む）をサーバ経由で動的に追加や更新可能なアーキテクチャを採用した。策展者は、提供されるツールキットに従い AR 展品（Node）を作成し、サーバへアップロードするだけで、恒久的なアクセスが可能となる。一方、鑑賞者は単一のクライアントアプリ（ARShow）を使用し、会場の QR コードをスキャンするだけで、即座に該当する作品コンテンツをダウンロードし、鑑賞を開始することができる。この設計により、ハードウェアやアプリの更新に依存しない作品の永続性と、直感的かつ統一された鑑賞体験の両立を目指している。

\clearpage
% 設計思想の図
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=80mm]{./figs/提案システム/設計思想.png}
\caption[設計思想]{設計思想 [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}

\section{開発環境}

本節では、本システムの構築および動作検証に使用したハードウェアおよびソフトウェア環境について述べる。

\subsection{ハードウェア}

本システムの開発および実行には、コンテンツ制作とサーバホスティングを行う PC と、AR体験を提供する HMD（Head Mounted Display）を用いた。

開発用PC（図\ref{fig:pc}）には、Windows 11 Professional（25H2）を搭載したワークステーションを使用した。Windows 環境を採用した主な理由は、Meta Quest Link 機能を利用することで、実機へのビルドしてインストールを行うことなく、Unity エディタ上で直接 AR 空間の動作確認が可能となり、開発効率が著しく向上するためである。

% PCの図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ハードウェア/PC.png}
\caption[PC]{開発に使用したPCの外観}
\label{fig:pc}
\end{figure}

本研究で使用したPCの具体的なハードウェア構成を表\ref{table:pc_spec}に示す。

% PCスペック表
\begin{table}[htbp]
  \caption[開発用PCの仕様]
  {開発用PC (Redmi G Pro 2024) のハードウェア構成}
  \label{table:pc_spec}
  \centering
  \begin{tabular}{lll}
  \hline
  \multicolumn{1}{|l||}{分類} & \multicolumn{1}{l|}{項目} & \multicolumn{1}{l|}{仕様} \\ \hline \hline
  \multicolumn{1}{|l||}{General}  & \multicolumn{1}{l|}{Model Name}  & \multicolumn{1}{l|}{Redmi G Pro 2024}  \\ \hline
  \multicolumn{1}{|l||}{System}  & \multicolumn{1}{l|}{OS}  & \multicolumn{1}{l|}{Windows 11 Professional}  \\ \hline
  \multicolumn{1}{|l||}{Hardware} & \multicolumn{1}{l|}{CPU} & \multicolumn{1}{l|}{Intel Core i7-14650HX} \\ \hline
  \multicolumn{1}{|l||}{Hardware}  & \multicolumn{1}{l|}{GPU}  & \multicolumn{1}{l|}{NVIDIA GeForce RTX 4060 Laptop}  \\ \hline
  \multicolumn{1}{|l||}{Hardware}  & \multicolumn{1}{l|}{Memory (RAM)}  & \multicolumn{1}{l|}{32 GB (DDR5)}  \\ \hline
  \multicolumn{1}{|l||}{Hardware}  & \multicolumn{1}{l|}{Storage}  & \multicolumn{1}{l|}{1 TB SSD (PCIe 4.0)}  \\ \hline
  \end{tabular}
\end{table}

鑑賞用デバイスには、ビデオシースルー機能を備えたスタンドアロン型 HMD である Meta Quest 3（図\ref{fig:quest3}）を採用した。また、開発 PC 機と HMD の接続には、大容量データの高速転送および安定したストリーミングを実現するため、転送速度 2.5Gbps 以上の帯域を持つ USB-C ケーブル（図\ref{fig:cable}）を使用した。

\begin{figure}[htbp]
\centering
% Meta Quest 3の図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/ハードウェア/MetaQuest3.png}
  \caption[MetaQuest3]{MetaQuest3 [5]．}
  \label{fig:quest3}
\end{minipage}
\hfill
% USB-Cケーブルの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/ハードウェア/USBCケーブル.png}
  \caption[USBCケーブル]{USBCケーブル [5]．}
  \label{fig:cable}
\end{minipage}
\end{figure}

ここで、Meta Quest 3 の主要仕様を表\ref{table:quest3_spec}にまとめる。

\clearpage
% Meta Quest 3のスペック表
\begin{table}[htbp]
  \caption[Meta Quest 3の仕様]
  {実験に使用したHMD (Meta Quest 3) の主な仕様}
  \label{table:quest3_spec}
  \centering
  \begin{tabular}{lll}
  \hline
  \multicolumn{1}{|l||}{分類} & \multicolumn{1}{l|}{項目} & \multicolumn{1}{l|}{仕様} \\ \hline \hline
  \multicolumn{1}{|l||}{General}  & \multicolumn{1}{l|}{Model}  & \multicolumn{1}{l|}{Meta Quest 3}  \\ \hline
  \multicolumn{1}{|l||}{Processor}  & \multicolumn{1}{l|}{SoC}  & \multicolumn{1}{l|}{Snapdragon XR2 Gen 2}  \\ \hline
  \multicolumn{1}{|l||}{Display} & \multicolumn{1}{l|}{Resolution} & \multicolumn{1}{l|}{2064 $\times$ 2208 pixels per eye} \\ \hline
  \multicolumn{1}{|l||}{Display}  & \multicolumn{1}{l|}{Refresh Rate}  & \multicolumn{1}{l|}{90 Hz / 120 Hz}  \\ \hline
  \multicolumn{1}{|l||}{Optics}  & \multicolumn{1}{l|}{Field of View}  & \multicolumn{1}{l|}{110$^\circ$ (H) / 96$^\circ$ (V)}  \\ \hline
  \multicolumn{1}{|l||}{Memory}  & \multicolumn{1}{l|}{RAM}  & \multicolumn{1}{l|}{8 GB}  \\ \hline
  \multicolumn{1}{|l||}{Camera}  & \multicolumn{1}{l|}{Passthrough}  & \multicolumn{1}{l|}{Full-color (4 MP, 18 PPD)}  \\ \hline
  \end{tabular}
\end{table}

本研究で言及した USB-C ケーブルの主要仕様を表\ref{table:cable_spec}にまとめる。

% ケーブルのスペック表
\begin{table}[htbp]
  \caption[USBケーブルの仕様]
  {HMDとPCの接続に使用したUSBケーブルの仕様}
  \label{table:cable_spec}
  \centering
  \begin{tabular}{lll}
  \hline
  \multicolumn{1}{|l||}{分類} & \multicolumn{1}{l|}{項目} & \multicolumn{1}{l|}{仕様} \\ \hline \hline
  \multicolumn{1}{|l||}{Interface}  & \multicolumn{1}{l|}{Connector Type}  & \multicolumn{1}{l|}{USB Type-C to Type-C}  \\ \hline
  \multicolumn{1}{|l||}{Standard}  & \multicolumn{1}{l|}{USB Standard}  & \multicolumn{1}{l|}{USB 3.2 Gen 1}  \\ \hline
  \multicolumn{1}{|l||}{Performance} & \multicolumn{1}{l|}{Max Transfer Rate} & \multicolumn{1}{l|}{5 Gbps} \\ \hline
  \multicolumn{1}{|l||}{Physical}  & \multicolumn{1}{l|}{Length}  & \multicolumn{1}{l|}{5.0 m}  \\ \hline
  \multicolumn{1}{|l||}{Material}  & \multicolumn{1}{l|}{Core Type}  & \multicolumn{1}{l|}{Optical Fiber}  \\ \hline
  \end{tabular}
\end{table}

ネットワーク環境として、本研究ではLAN（構内通信網）内での運用を想定し、スマートフォン（図\ref{fig:smartphone}）のテザリング機能を用いて PC と HMD を同一ネットワークに接続した。なお、スマートフォン再起動等による IP アドレスの変更に対応するため、開発機側で固定 IP 設定もしくは動的 IP の確認手順を確立して運用した。

\clearpage
% スマートフォンの図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ハードウェア/スマートフォン.png}
\caption[スマートフォン]{スマートフォン [5]．}
\label{fig:smartphone}
\end{figure}

本研究で使用したスマートフォンの主な仕様を表\ref{table:smartphone_spec}に示す。

% スマートフォンのスペック表
\begin{table}[htbp]
  \caption[スマートフォンの仕様]
  {使用したスマートフォンの仕様一覧}
  \label{table:smartphone_spec}
  \centering
  \begin{tabular}{lll}
  \hline
  \multicolumn{1}{|l||}{分類} & \multicolumn{1}{l|}{項目} & \multicolumn{1}{l|}{仕様} \\ \hline \hline
  \multicolumn{1}{|l||}{Device}  & \multicolumn{1}{l|}{Model Name}  & \multicolumn{1}{l|}{Google Pixel 7a}  \\ \hline
  \multicolumn{1}{|l||}{System}  & \multicolumn{1}{l|}{OS Version}  & \multicolumn{1}{l|}{Android 13}  \\ \hline
  \multicolumn{1}{|l||}{Network} & \multicolumn{1}{l|}{Wi-Fi Standard} & \multicolumn{1}{l|}{IEEE 802.11ax (Wi-Fi 6E)} \\ \hline
  \multicolumn{1}{|l||}{Network}  & \multicolumn{1}{l|}{Tethering Band}  & \multicolumn{1}{l|}{5 GHz / 2.4 GHz}  \\ \hline
  \multicolumn{1}{|l||}{Hardware}  & \multicolumn{1}{l|}{Processor (SoC)}  & \multicolumn{1}{l|}{Google Tensor G2}  \\ \hline
  \multicolumn{1}{|l||}{Hardware}  & \multicolumn{1}{l|}{Memory (RAM)}  & \multicolumn{1}{l|}{8 GB}  \\ \hline
  \end{tabular}
\end{table}

\subsection{ソフトウェア}

本システムのソフトウェア開発環境は、Unity を統合開発環境の中核とし、Meta 社が提供する XR 開発キットおよびサードパーティ製のライブラリ群によって構成されている。

主要な開発プラットフォームとして Unity を使用し、Meta Quest 3 のパススルー機能や空間認識機能を利用するために Meta XR All-in-One SDK および OpenXR プラグインを導入した。これにより、高精度なパススルー機能や空間アンカー、ハンドトラッキングといった固有機能へのアクセスを可能にしている。同時に、標準規格である OpenXR Plugin を併用することで、将来的なデバイス互換性と拡張性を担保した。ユーザーインターフェース（UI）の構築においては、Meta Horizon OS UI Set（図\ref{fig:uiset}）を採用した。Quest のシステム標準 UI と親和性の高いデザインコンポーネントを使用することで、ユーザーに対して違和感のない、直感的な操作体験を提供することを目的としている。

% UI Setの図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ソフトウェア/MetaHorizonOSUISet.png}
\caption[MetaHorizonOSUISet]{MetaHorizonOSUISet [5]．}
\label{fig:uiset}
\end{figure}

また、本システムのアーキテクチャ上の特徴として、動的なコード実行（ホットアップデート）機能の実装が挙げられる。通常の Unity IL2CPP ビルドでは困難な、実行時のロジック更新を実現するため、C\# インタープリタフレームワークである HybridCLR を組み込んだ。これにより、実機への再インストールを行うことなく機能の拡張が可能となり、開発サイクルの大幅な効率化を実現している。その他、外部入力機能として、QR コード認識には軽量かつ高速な ZXing.unity を、音声コマンド認識には Meta Wit.ai を活用した。

本システムの開発および実装に使用した主要なプラグインとライブラリ一覧を表\ref{table:dev_tools_spec}に示す。

% Unityとツールの表
\begin{table}[htbp]
  \caption[開発環境およびライブラリ構成]
  {本システムで使用した開発環境およびライブラリのバージョン一覧}
  \label{table:dev_tools_spec}
  \centering
  \begin{tabular}{lll}
  \hline
  \multicolumn{1}{|l||}{分類} & \multicolumn{1}{l|}{名称} & \multicolumn{1}{l|}{バージョン} \\ \hline \hline
  \multicolumn{1}{|l||}{Platform}  & \multicolumn{1}{l|}{Unity}  & \multicolumn{1}{l|}{6000.0.62f1}  \\ \hline
  \multicolumn{1}{|l||}{XR Plugin}  & \multicolumn{1}{l|}{Meta XR All-in-One SDK}  & \multicolumn{1}{l|}{v81}  \\ \hline
  \multicolumn{1}{|l||}{XR Plugin} & \multicolumn{1}{l|}{OpenXR Plugin} & \multicolumn{1}{l|}{v1.1.54} \\ \hline
  \multicolumn{1}{|l||}{Library}  & \multicolumn{1}{l|}{HybridCLR}  & \multicolumn{1}{l|}{v8.5.0}  \\ \hline
  \multicolumn{1}{|l||}{Library}  & \multicolumn{1}{l|}{ZXing.unity}  & \multicolumn{1}{l|}{v3.5.4}  \\ \hline
  \end{tabular}
\end{table}

実機へのデプロイ、パフォーマンス監視、および画面収録などのデバイス管理プロセスには、公式の統合開発ツールである Meta Quest Developer Hub（図\ref{fig:mqdh}）を使用した。また、PC 側でのレンダリング検証や Unity エディタの Play Mode を活用した迅速なデバッグを行うため、Meta Horizon Link（図\ref{fig:link}）による有線接続環境を構築した。

\clearpage
\begin{figure}[htbp]
\centering
% MQDHの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/ソフトウェア/MQDH.png}
  \caption[Meta Quest Developer Hub]{Meta Quest Developer Hub [5]．}
  \label{fig:mqdh}
\end{minipage}
\hfill
% Linkの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/ソフトウェア/MetaHorizonLink.png}
  \caption[Meta Horizon Link]{Meta Horizon Link [5]．}
  \label{fig:link}
\end{minipage}
\end{figure}

サーバサイドの実装においては、クライアントサイド（Unity）と主要開発言語を C\# に統一することで、データモデルの共有やコンテキストスイッチの低減を図るため、ASP.NET Core を採用した。特に、軽量かつ高速なレスポンスが求められるため、Minimal API 構成で実装している。

コーディングおよびデバッグ環境には、軽量かつ拡張性に優れた Visual Studio Code を選定した。Microsoft 社が提供する C\# Dev Kit および Unity 拡張機能を導入することで、コード補完やブレークポイントによるデバッグ効率を最大化した。

本システムの開発および実装に使用した主要なソフトウェア開発環境一覧を表\ref{table:software_env}に示す。

% ソフトウェア開発環境の表
\begin{table}[htbp]
  \caption[開発支援ツールおよびサーバ環境]
  {デバッグツール、サーバフレームワークおよびエディタのバージョン一覧}
  \label{table:software_env}
  \centering
  \begin{tabular}{lll}
  \hline
  \multicolumn{1}{|l||}{分類} & \multicolumn{1}{l|}{名称} & \multicolumn{1}{l|}{バージョン} \\ \hline \hline
  \multicolumn{1}{|l||}{Tool}  & \multicolumn{1}{l|}{Meta Quest Developer Hub}  & \multicolumn{1}{l|}{v3.2}  \\ \hline
  \multicolumn{1}{|l||}{Tool}  & \multicolumn{1}{l|}{Meta Horizon Link}  & \multicolumn{1}{l|}{v83.0.0.224.349}  \\ \hline
  \multicolumn{1}{|l||}{Framework} & \multicolumn{1}{l|}{ASP.NET Core} & \multicolumn{1}{l|}{v10.0.1} \\ \hline
  \multicolumn{1}{|l||}{Editor}  & \multicolumn{1}{l|}{Visual Studio Code}  & \multicolumn{1}{l|}{v1.108}  \\ \hline
  \end{tabular}
\end{table}

\section{システム構成}

本節では、提案システムの具体的な構成要素と、それらが連携するアーキテクチャについて詳細に述べる。
提案システムは大きく分けて、
\begin{itemize}
    \item キュレーターが展示コンテンツを制作および出力するためのUnityプロジェクト「ARShowNode」
    \item 鑑賞者が使用する閲覧用アプリケーション「ARShow」
    \item コンテンツを保持かつ配信する「静的ファイルサーバ」
\end{itemize}
の三つ要素から構成される。提案システムの全体構成を図\ref{fig:system_overview}に示す。

% 提案システムの全体構成図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/提案システムの全体構成図.png}
\caption[提案システムの全体構成図]{提案システムの全体構成図 [5]．}
\label{fig:system_overview}
\end{figure}

\subsection{ARShowNode}

ARShowNode は、キュレーター（制作者）向けに提供される Unity プロジェクトである（図\ref{fig:arshownode_global}）。本プロジェクトは、AR 展品（Node）を単位（AssetBundle）として管理し、各 Node には 3D モデル、音声、映像、および動的ロジック（C\# スクリプト）が含まれる。

% ARShowNode Unityプロジェクトの全体図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ARShowNode/ARShowNodeGlobal.png}
\caption[ARShowNodeGlobal]{ARShowNodeGlobal [5]．}
\label{fig:arshownode_global}
\end{figure}

\subsubsection{HybridCLR}

本システムにおける技術的な核心は、HybridCLR の採用にある。通常の Unity 製アプリ（IL2CPP ビルド）では、ビルド後に C\# スクリプトの挙動を変更することは不可能である。しかし、HybridCLR を導入することで、C\# コードをコンパイルした DLL をアセットとして扱い、実行時にインタープリタモードでロードして実行することが可能となる（図\ref{fig:hybridclr_tool}）。ARShowNode では、キュレーターが記述したスクリプトを HybridCLR によって AOT（Ahead-Of-Time）メタデータとホットアップデート用 DLL に変換し、これらを AssetBundle に含めることで、アプリ本体の更新を伴わない展示ロジックの配信を実現している。

\begin{figure}[htbp]
\centering
% HybridCLRツールの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/ARShowNode/HybridCLRTool.png}
  \caption[HybridCLRTool]{HybridCLRTool [5]．}
  \label{fig:hybridclr_tool}
\end{minipage}
\hfill
% 提案されたUnityツールの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/ARShowNode/ARShowTool.png}
  \caption[ARShowTool]{ARShowTool [5]．}
  \label{fig:arshow_tool}
\end{minipage}
\end{figure}

\subsubsection{制作のための Unity ツール}

本研究では、キュレーターの作業負荷を軽減するため、ARShowNode プロジェクト内に専用の Unity エディタ拡張ツールを実装した（図\ref{fig:arshow_tool}）。このツールはメニューバーからアクセス可能であり、以下の四つの機能を順次実行することで展示データの配信を行う。

\begin{enumerate}
    \item \textbf{DLLの複製}: HybridCLR によって生成された AOT メタデータの DLL およびホットアップデートの DLL を、Unity プロジェクト内の Assets ディレクトリへコピーする。複数作品（Node）を同時制作する場合、各 Node に対応した DLL を複製する。
    \item \textbf{AssetBundleのビルド}: 事前に設定されたラベル（Node0, Node1...等の識別子）に基づき、各作品のリソースと DLL を含んだ AssetBundle を生成する。
    \item \textbf{QRコード生成}: 各 AssetBundle の識別子（Node名）情報を格納した QR コード画像を自動生成する。
    \item \textbf{アップロード}: 生成された AssetBundle 群を、稼働中の静的ファイルサーバへ一括アップロードする。
\end{enumerate}

\subsubsection{Node}

「Node」は、本システムにおける展示作品の単位であり、一つの AssetBundle に対応している。各 Node は、展示物の実体である Prefab、関連する設定ファイル、メディアアセット（画像、音響）、および制御用スクリプトのアセンブリの集合体である。本研究では、図\ref{fig:node_global}に示すように、同一 Unity プロジェクト内で複数の Node（Node0, Node1, Node2...）を並行して制作と管理可能な構造としている。

\clearpage
% 三つNodeの全体図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/Node/NodeGlobal.png}
\caption[NodeGlobal]{NodeGlobal [5]．}
\label{fig:node_global}
\end{figure}

\subsubsection{エントリポイント（Entry.cs）}

動的にロードされたスクリプトを、実行時（Runtime）に正しくゲームオブジェクトにアタッチし機能させるため、本システムでは「Entry.cs」という規約に基づいたエントリポイントスクリプトを導入した（図\ref{fig:entry_global}）。

Entry.cs は各 Node の初期化ロジックを担い、AssetBundle のロード完了後、ARShow アプリ側から明示的に呼び出されることで、Prefab のインスタンス化や依存コンポーネントのセットアップを実行する。実装コードの一部を図\ref{fig:entry_code}に示す。

\begin{figure}[htbp]
\centering
% 三つNodeに分けるEntry.csの全体図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/ARShowNode/EntryGlobal.png}
  \caption[EntryGlobal]{EntryGlobal [5]．}
  \label{fig:entry_global}
\end{minipage}
\hfill
% Entry.csのコードの一部図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/ARShowNode/EntryCode.png}
  \caption[EntryCode]{EntryCode [5]．}
  \label{fig:entry_code}
\end{minipage}
\end{figure}

通常の Unity 開発では Inspector 上でスクリプトをアタッチするが、別プロジェクトでビルドされた AssetBundle 内のスクリプトを復元する場合、GUID の不整合等により参照が切れる問題がある。これを回避するため、本システムでは HybridCLR の推奨手法に基づき、実行時に「GameObject.AddComponent」メソッドを介してスクリプトを動的に付与する方式を採用した。

\subsubsection{AssetBundle}

Unity の AssetBundle 機能を利用し、Node ごとのリソースとコードをパッケージ化している。前述の通り、本システムでは AssetBundle 内に HybridCLR 用の DLL を含める点が特徴である（図\ref{fig:assetbundle_global}）。これにより、3D モデルやテクスチャだけでなく、インタラクション等の仕組みも含めた完全な展示パッケージとして配信される。

% 提案されたUnityツールにより生成したAssetBundleの例
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ARShowNode/AssetBundleGlobal.png}
\caption[AssetBundleGlobal]{AssetBundleGlobal [5]．}
\label{fig:assetbundle_global}
\end{figure}

\subsubsection{WitAI}

音声操作を実現するため、Meta 社が提供する自然言語処理サービス Wit.ai を導入した（図\ref{fig:witai_config}）。Node 内で音声認識が必要な場合、ユーザーの音声入力は Meta XR Voice SDK を通じてテキスト化され、Wit.ai サーバへ送信される。サーバ上で事前に定義されたインテント（Intent）やエンティティ（Entity）の解析が行われ、その結果に基づいて Unity 側の関数がトリガーされる仕組みである。本研究では、中国語による音声コマンド制御の事例を実装した。

% WitAI配置図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ARShowNode/WitAI配置.png}
\caption[WitAI配置]{WitAI配置 [5]．}
\label{fig:witai_config}
\end{figure}

\subsection{ARShow}

ARShow は、Meta Quest 3 上で動作する鑑賞者用アプリケーションである（図\ref{fig:arshow_global}）。本アプリは、QR コードのスキャン、AssetBundle のダウンロード、および動的コンテンツの再生環境を提供するコンテナとして機能する。

% ARShow Unityプロジェクトの全体図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ARShow/ARShowGlobal.png}
\caption[ARShowGlobal]{ARShowGlobal [5]．}
\label{fig:arshow_global}
\end{figure}

\subsubsection{スキャンモード}

アプリ起動後、ユーザーは UI 上の「ScanQr」ボタンを押下することでスキャンモードへ移行する（図\ref{fig:scan_qr_button}）。このモードでは、パススルーカメラの映像上に QR コード検出用のガイドが表示され、認識待機状態となる。

% ScanQrボタンの図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ARShow/ScanQrボタン.png}
\caption[ScanQrボタン]{ScanQrボタン [5]．}
\label{fig:scan_qr_button}
\end{figure}

\subsubsection{QR Code 検出}

QR コードの認識には ZXing.unity ライブラリを使用し、Quest 3 のカメラ映像からフレームごとの解析を行う。有効な QR コード（AssetBundle の識別子）が検出されると、スキャンモードを終了し、コンテンツのロード処理へ移行する。同一の QR コードを再スキャンした場合は、重複ロードを避けるためコンソールへ警告を表示する等の制御を行っている。

\subsubsection{アセットロード}

識別子に基づき、サーバから該当する AssetBundle をダウンロードする。ダウンロード中は、QR コードの物理位置にプログレスバー（進捗率）を空間表示し、ユーザーへのフィードバックを行う。初 AssetBundle のダウンロードプログレスが図\ref{fig:node0_progress}に示され、後続のものが図\ref{fig:node2_progress}に示される。

\begin{figure}[htbp]
\centering
% 初のAssetBundleダウンロードプログレスの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0Progress.png}
  \caption[Node0Progress]{Node0Progress [5]．}
  \label{fig:node0_progress}
\end{minipage}
\hfill
% 後続のAssetBundleダウンロードプログレスの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node2Progress.png}
  \caption[Node2Progress]{Node2Progress [5]．}
  \label{fig:node2_progress}
\end{minipage}
\end{figure}

ダウンロード完了後、システムは以下の手順でアセットを展開する。

\begin{enumerate}
    \item AssetBundle から HybridCLR 用の AOT メタデータ DLL をメモリ上に展開し、IL2CPP ランタイムに登録する。
    \item ホットアップデート用 DLL をロードする。
    \item ロードされたアセンブリ内から Entry.cs のエントリポイントメソッドをリフレクションを用いて呼び出す。
\end{enumerate}

これにより、図\ref{fig:node0_ui_1}に示すように AR 展品がシーン内に初期化され、インタラクションが開始される。

% Node0のUIの図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/Node/Node0UI.png}
\caption[Node0UI]{Node0UI [5]．}
\label{fig:node0_ui_1}
\end{figure}

\subsubsection{AOT ストリッピングの防止（AOT Stripping Prevention）}

Unity の IL2CPP ビルドでは、ビルド時に使用されていないコードや型情報はファイルサイズ削減のために削除（ストリッピング）される。しかし、動的にロードされる Node 側のスクリプトが、アプリ本体側で削除された型に依存している場合、実行時エラーが発生する。

これを防ぐため、本システムでは Link.xml ファイルを定義し（図\ref{fig:linkxml_config}）、Node で使用する可能性のあるアセンブリや型を明示的に記述することで、ビルド時のストリッピングを回避している。これにより、ARShowNode で開発された任意のスクリプトが、ARShow アプリ上で正しく動作することを保証している。

% Link.xmlコードの配置図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ARShow/Linkxml配置.png}
\caption[Linkxml配置]{Linkxml配置 [5]．}
\label{fig:linkxml_config}
\end{figure}

\subsection{サーバ}

AssetBundle のホスティングには、開発 PC 機上で動作する ASP.NET Core ベースの静的ファイルサーバを用いた。本サーバは Minimal API 構成で実装されており、HTTP リクエストに応じて AssetBundle ファイルを提供する単純かつ高速な仕様となっている。

「ARShow」プロジェクトのメニューバーには、図\ref{fig:server_tool}に示すように、このサーバの「起動」「停止」「ディレクトリ清掃」を制御する機能も統合されており、展示運用時のサーバ管理を容易にしている。なお、開発環境のLAN（構内通信網）においては、ARShow アプリにサーバから AssetBundle をダウンロードする用の IP アドレスを開発 PC 機の実際アドレースと一致させる必要がある。

% 提案されたServerToolの図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ARShow/ServerTool.png}
\caption[ServerTool]{ServerTool [5]．}
\label{fig:server_tool}
\end{figure}

\section{UI とインタラクション}

本節では、本システムにおいて実装された三つ代表的な展示作品（Node）を例に挙げ、鑑賞者が体験するユーザーインターフェース（UI）およびインタラクションの詳細について述べる。各 Node はそれぞれ異なるメディア形式（複合 UI、映像、3D モデル）を扱っており、システムの汎用性を示している。

\subsection{Node0: 複合的な AR 展示インターフェース}

Node0 は、本システムの中で最も機能的に複雑な展示例であり、文化財の 3D モデル表示と解説テキスト、および音声操作を組み合わせた複合的な AR コンテンツである。実際の UI 表示を図\ref{fig:node0_ui_2}に示す。

% Node0のUIの図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/Node/Node0UI.png}
\caption[Node0UI]{Node0UI [5]．}
\label{fig:node0_ui_2}
\end{figure}

\subsubsection{インターフェース構成}

本 Node の UI は、Meta Horizon OS UI Set をベースに構築されており、Meta Quest の標準的なシステム UI と親和性の高いデザインを採用している。画面構成は主に「音声のテキスト化フィードバック」と「操作用テキストキャンバス」の二つのモジュールから成る。テキストキャンバスは、機能に応じて以下の三つのセクションに区分されている。

\begin{itemize}
    \item \textbf{スクリーンリーダー制御}: 図\ref{fig:node0_reader}に示すように、解説音声の「再生（Play）」「一時停止（Pause）」「停止（Stop）」を行うボタン群が配置されている。
    \item \textbf{多国言語制御}: 文化財の解説テキストを表示するエリアおよび言語選択ドロップダウンメニューである。言語切り替えにより、テキストと読み上げ音声が即座に変更される。
    \item \textbf{音声コマンド制御}: 「Listen」ボタンと認識結果を表示するテキストボックスから構成される（図\ref{fig:node0_listen}）。
\end{itemize}

\begin{figure}[htbp]
\centering
% Node0ReaderボタンUIの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0UIReader.png}
  \caption[Node0UIReader]{Node0UIReader [5]．}
  \label{fig:node0_reader}
\end{minipage}
\hfill
% Node0ListenボタンUIの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0UIListen.png}
  \caption[Node0UIListen]{Node0UIListen [5]．}
  \label{fig:node0_listen}
\end{minipage}
\end{figure}

\subsubsection{インタラクション}

鑑賞者は、ハンドトラッキング機能を用いた以下のように直感的な操作が可能である。

\begin{itemize}
    \item \textbf{タッチ操作（Poke）}: 仮想ボタンを指先で直接押すことで、再生制御やモード切替を行う（図\ref{fig:node0_poke}）。
    \item \textbf{遠隔操作（Ray）}: 手から発せられるレイ（光線）を用いて、離れた位置にある UI 要素を選択と操作する（図\ref{fig:node0_ray}）。
    \item \textbf{把持操作（Grab）}: UI パネルや 3D モデルを「掴む」ジェスチャにより、鑑賞しやすい位置や角度へ自由に移動させることができる（図\ref{fig:node0_grab}）。
\end{itemize}

\begin{figure}[htbp]
\centering
% Node0ボタンUIのPoke図
\begin{minipage}{0.32\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0UIPoke.png}
  \caption[Node0UIPoke]{Node0UIPoke [5]．}
  \label{fig:node0_poke}
\end{minipage}
\hfill
% Node0ボタンUIのRay図
\begin{minipage}{0.32\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0UIRay.png}
  \caption[Node0UIRay]{Node0UIRay [5]．}
  \label{fig:node0_ray}
\end{minipage}
\hfill
% Node0ボタンUIのGrab図
\begin{minipage}{0.32\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0UIGrab.png}
  \caption[Node0UIGrab]{Node0UIGrab [5]．}
  \label{fig:node0_grab}
\end{minipage}
\end{figure}

これらのインタラクションを実現するため、技術的には PointableCanvasModule システムを利用している（図\ref{fig:pointable_canvas}）。通常、このイベントシステムは Unity シーン内に常駐する必要があるが、本システムでは動的にロードされる Node 側（ARShowNode）で定義されたイベント設定を、実行時に本体アプリ（ARShow）のシーンへ正しく引き継ぐ仕組みを実装することで、スムーズな操作性を確保している。

% PointableCanvasModuleの配置図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/ARShow/PointableCanvasModule.png}
\caption[PointableCanvasModule]{PointableCanvasModule [5]．}
\label{fig:pointable_canvas}
\end{figure}

\subsubsection{音声コマンド制御}

「Listen」ボタンを押下すると音声認識モードへ移行し、Wit.ai を介したボイスコマンドによる操作が可能となる。図\ref{fig:voice_ignore}と図\ref{fig:voice_status}に示すように、システムは待機状態（Ignore）から聞き取り状態（Listen）へと遷移する。

\begin{figure}[htbp]
\centering
% Node0のVoiceIgnoreStatus図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0VoiceIgnoreStatus.png}
  \caption[Node0VoiceIgnoreStatus]{Node0VoiceIgnoreStatus [5]．}
  \label{fig:voice_ignore}
\end{minipage}
\hfill
% Node0のVoiceListenStatus図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0VoiceListenStatus.png}
  \caption[Node0VoiceListenStatus]{Node0VoiceListenStatus [5]．}
  \label{fig:voice_status}
\end{minipage}
\end{figure}

例えば、所定のキーワードを発話することで、ボタン操作なしに解説の再生や言語変更を行うことができる。認識された発話内容は左側 UI モジュールにテキストとしてフィードバックされ、確実な入力を支援する。

図\ref{fig:voice_rec_ch}と図\ref{fig:voice_rec_en}に中国語および英語の言語に切り替えた結果を示す。

\begin{figure}[htbp]
\centering
% Node0のVoiceNviChの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0VoiceNviCh.png}
  \caption[Node0VoiceNviCh]{Node0VoiceNviCh [5]．}
  \label{fig:voice_rec_ch}
\end{minipage}
\hfill
% Node0のVoiceNviEnの図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0VoiceNviEn.png}
  \caption[Node0VoiceNviEn]{Node0VoiceNviEn [5]．}
  \label{fig:voice_rec_en}
\end{minipage}
\end{figure}

図\ref{fig:voice_start}と図\ref{fig:voice_stop}に音声コマンドによる再生開始と停止の挙動を示す。

\begin{figure}[htbp]
\centering
% Node0のVoicePlayStart図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0VoicePlayStart.png}
  \caption[Node0VoicePlayStart]{Node0VoicePlayStart [5]．}
  \label{fig:voice_start}
\end{minipage}
\hfill
% Node0のVoicePlayStop図
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./figs/提案システム/Node/Node0VoicePlayStop.png}
  \caption[Node0VoicePlayStop]{Node0VoicePlayStop [5]．}
  \label{fig:voice_stop}
\end{minipage}
\end{figure}

\subsection{Node1: 映像コンテンツの空間配置}

Node1 は、映像メディアを AR 空間内に配置する展示例である（図\ref{fig:node1_ui}）。Unity のプリミティブ形状である Quad（板ポリゴン）に Video Player コンポーネントを付加し、独自の録画映像と音声を再生する構成となっている。本 Node にも Grab インタラクションが付与されており、鑑賞者は空中に浮かぶスクリーンを手に取り、壁面に配置したり、目の前に引き寄せて細部を確認したりといった、物理的なスクリーンと同様の取り回しが可能である。これは、動画解説パネルとしての利用を想定した実装である。

% Node1のUIの図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/Node/Node1UI.png}
\caption[Node1UI]{Node1UI [5]．}
\label{fig:node1_ui}
\end{figure}

\subsection{Node2: 3D モデル（文化財）の展示}

Node2 は、静的な 3D オブジェクトの展示に特化した最小構成の例である（図\ref{fig:node2_ui}）。ここでは、Sketchfab より取得した青銅器の 3D モデル（glTF 形式）を Prefab 化し、AssetBundle として配信している。Node1 同様、Grab インタラクションが設定されており、鑑賞者は貴重な文化財モデルを仮想的に手に取り、あらゆる角度から詳細に観察することができる。この Node は、複雑なスクリプトを含まない純粋なアセットデータも、本システムを通じて問題なく配信や操作可能であることを実証している。

\clearpage
% Node2のUIの図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/Node/Node2UI.png}
\caption[Node2UI]{Node2UI [5]．}
\label{fig:node2_ui}
\end{figure}

\section{ワークフロー}

本節では、本システムを用いた AR 展示の制作から鑑賞に至るまでの具体的なワークフローについて、制作サイド（キュレーター）と鑑賞サイド（閲覧者）の双方の視点から述べる。

\subsection{制作サイド（キュレーター）}

キュレーター側の作業は、Unity プロジェクト「ARShowNode」を用いて行われる。制作から公開に至る全体のワークフローを図\ref{fig:creator_workflow}に示す。

% 制作者ワークフロー図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/制作者ワークフロー.png}
\caption[制作者ワークフロー]{制作者ワークフロー [5]．}
\label{fig:creator_workflow}
\end{figure}

\subsubsection{ARShowNode プロジェクトの配置}

まず、キュレーターは提供される「ARShowNode」プロジェクトを開発環境に展開する。このプロジェクトには、Meta XR All-in-One SDK、HybridCLR、および本研究で開発した専用ツールキット等の依存ライブラリが事前設定されている。キュレーターは、Unity エディタ上でコンパイルエラーがない状態を確認し、自身のコンテンツ（Prefab や スクリプト）の制作を開始する。

\subsubsection{Assembly のビルド}

作品のロジック（C\# スクリプト）をホットアップデート可能な形式に変換するため、HybridCLR のビルド機能を実行する。まず、HybridCLR メニューから Install を実行し、環境を初期化する。次に CompileDll コマンドを実行し、ターゲットプラットフォーム（Android）向けの DLL（AOT メタデータおよびホットアップデート用アセンブリ）を出力する。そして Generate コマンドを実行し、ブリッジコード等を生成する。

\subsubsection{AssetBundle の事前準備}

DLL のビルド完了後、上述の本研究が提供した Unity ツール（ARShowTool）を用いて、以下の手順で配信準備を行う。

\begin{enumerate}
    \item \textbf{DLL の配置}: ツールメニューの「Move DLLs」を実行し、生成されたDLLファイルを Unity プロジェクトの Assets フォルダへ複製する。
    \item \textbf{バンドル設定}: 各作品のリソース（Prefab, DLL 等）に対し、一意の AssetBundle ラベル（例: node0）を付与する。
    \item \textbf{ビルド実行}: ツールメニューの「Build AssetBundles」を実行する。これにより、ラベル付けされたリソースが一つの AssetBundle ファイルとしてパッケージ化される。
    \item \textbf{QR コード生成}: ツールメニューの「Generate QR」を実行し、各 AssetBundle に対応する QR コード画像を生成する。
\end{enumerate}

\subsubsection{サーバへのアップロード}

最後に、ツールメニューの「Upload to Server」を実行する。これにより、生成された全ての AssetBundle ファイルが、LAN（構内通信網）内で稼働している静的ファイルサーバの公開ディレクトリへ自動的に転送される。以上で、展示コンテンツの公開作業は完了である。

\subsection{鑑賞サイド（鑑賞者）}

鑑賞者は、HMD（Meta Quest 3）を装着し、図\ref{fig:viewer_workflow}に示す手順で展示を体験する。

\clearpage
% 閲覧者ワークフロー図
\begin{figure}[htbp]
\centering
\includegraphics[width=80mm]{./figs/提案システム/閲覧者ワークフロー.png}
\caption[閲覧者ワークフロー]{閲覧者ワークフロー [5]．}
\label{fig:viewer_workflow}
\end{figure}

\subsubsection{ARShow AR APP のインストール}

事前に、Meta Quest Developer Hub（MQDH）等を経由して、閲覧用アプリ「ARShow」をデバイスにインストールする。

\subsubsection{スキャンモードによる開始}

アプリを起動すると、空間上に「ScanQr」ボタンが表示される。これをクリックすると、パススルーカメラを用いた QR コードスキャンモードに移行する。鑑賞者が展示会場に掲示された QR コードに視線を向けると、システムは自動的にコードを認識して解析する。

\subsubsection{プログラムの実行フロー}

QR コードの認識後、システムは以下のフローを自動的に実行する。

\begin{enumerate}
    \item \textbf{ダウンロード}: 解析された ID に基づき、サーバから対応する AssetBundle をダウンロードする。進捗状況は空間上のプログレスバーで可視化される。
    \item \textbf{アセンブリロード}: ダウンロード完了後、AssetBundle 内の AOT メタデータ DLL とホットアップデート DLL をメモリに展開する。
    \item \textbf{初期化（Entry Point）}: ロードされたアセンブリ内の Entry.cs を特定し、その初期化メソッドを実行する。この段階で、展示作品の Prefab がシーン内に生成（Instantiate）され、必要なコンポーネントが動的にアタッチされる。
    \item \textbf{登録と管理}: 生成された作品は ID と共に内部辞書に登録される。スキャンモードは終了し、鑑賞者は作品とのインタラクションが可能となる。
\end{enumerate}

なお、既にロード済みの QR コードを再スキャンした場合は、重複ロードを防ぐためコンソールに警告が表示され、およびスキャンモードが解除される仕様となっている。

