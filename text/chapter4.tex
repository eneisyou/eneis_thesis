\chapter{提案システム}
\label{exprmnt:physarum}

\section{設計思想}

本節では、本研究で提案したAR展示システムの設計思想について述べる。

本システムは、AR（拡張現実）を用いた芸術展示において、キュレーター（制作者）と鑑賞者の間に存在するコミュニケーションコストの削減、および展示コンテンツの持続可能な運用を解決することを主たる目的として設計された。従来のデジタル芸術展示、特にアプリベースのAR展示においては、策展者が作品を公開するためにアプリケーションそのものを配布する必要があり、更新のたびに再配布や再インストールが求められるという課題があった。また、展示会終了とともにアプリのサポートが終了し、作品の鑑賞が不可能になるケースも散見される。さらに、鑑賞者にとっても、展示ごとに異なる操作方法や導入手順を学習する必要があり、これが鑑賞体験への障壁となっていた。

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=100mm]{./figs/提案システム/設計思想.png}
\caption[設計思想]{設計思想 [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}

これらの課題に対し、本システムはキュレーターと鑑賞者を媒介するプラットフォームとしての役割を果たす。具体的には、UnityのAssetBundle機能とHybridCLRによるホットアップデート技術を組み合わせることで、アプリケーション本体を更新することなく、展示コンテンツ（ロジックを含む）をサーバ経由で動的に追加や更新可能なアーキテクチャを採用した。策展者は、提供されるツールキットに従いAR展品（Node）を作成し、サーバへアップロードするだけで、恒久的なアクセスが可能となる。一方、鑑賞者は単一のクライアントアプリ（ARShow）を使用し、会場のQRコードをスキャンするだけで、即座に該当する作品コンテンツをダウンロードし、鑑賞を開始することができる。この設計により、ハードウェアやアプリの更新に依存しない作品の永続性と、直感的かつ統一された鑑賞体験の両立を目指している。

\section{開発環境}

本節では、本システムの構築および動作検証に使用したハードウェアおよびソフトウェア環境について述べる。

\subsection{ハードウェア}

本システムの開発および実行には、コンテンツ制作とサーバホスティングを行うPCと、AR体験を提供するHMD（Head Mounted Display）を用いた。開発用PCには、Windows 11 Professional (25h2) を搭載したワークステーションを使用した。Windows環境を採用した主な理由は、Meta Quest Link機能を利用することで、実機へのビルドしてインストールを行うことなく、Unityエディタ上で直接VR/AR空間の動作確認が可能となり、開発効率が著しく向上するためである。鑑賞用デバイスには、ビデオシースルー機能を備えたスタンドアロン型HMDであるMeta Quest 3を採用した。また、開発機とHMDの接続には、大容量データの高速転送および安定した串流（ストリーミング）を実現するため、転送速度2.5Gbps以上の帯域を持つUSB-Cケーブルを使用した。ネットワーク環境として、本研究ではローカルエリアネットワーク（LAN）内での運用を想定し、スマートフォン（機種：[表1参照]）のテザリング機能を用いてPCとHMDを同一ネットワークに接続した。なお、スマートフォン再起動等によるIPアドレスの変更に対応するため、開発機側で固定IP設定もしくは動的IPの確認手順を確立して運用した。

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=100mm]{./figs/提案システム/ハードウェア/PC.png}
\caption[PC]{PC [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=100mm]{./figs/提案システム/ハードウェア/MetaQuest3.png}
\caption[MetaQuest3]{MetaQuest3 [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=100mm]{./figs/提案システム/ハードウェア/USBCケーブル.png}
\caption[USBCケーブル]{USBCケーブル [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=100mm]{./figs/提案システム/ハードウェア/スマートフォン.png}
\caption[スマートフォン]{スマートフォン [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}

[表1: 開発および実行に使用したハードウェアスペック一覧] （ここにPCのCPU/GPU/メモリ構成、Quest 3の仕様、スマートフォンの機種名を記載する表を挿入）

\subsection{ソフトウェア}

本システムのソフトウェア開発環境は、Unityを統合開発環境の中核とし、Meta社が提供するXR開発キットおよびサードパーティ製のライブラリ群によって構成されている。主要な開発プラットフォームとしてUnity（バージョン：[表2参照]）を使用し、Meta Quest 3のパススルー機能や空間認識機能を利用するためにMeta XR All-in-One SDKおよびOpenXRプラグインを導入した。UI構築には、QuestのシステムUIと親和性の高いMeta Horizon OS UI Setを採用した。 本システムの核となる動的コード実行（ホットアップデート）には、C\#インタープリタフレームワークであるHybridCLRを利用し、QRコードの認識にはZXing.unityを採用した。また、音声認識機能の実装にはMeta Wit.aiを活用している。実機へのデプロイおよび画面収録、デバッグには、Meta Quest Developer Hub (MQDH) およびMeta Quest Linkを使用した。 サーバサイドは、Unityと開発言語（C\#）を統一するため、ASP.NET Coreを用いたMinimal APIとして実装した。

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=100mm]{./figs/提案システム/ソフトウェア/MetaHorizonOSUISet.png}
\caption[MetaHorizonOSUISet]{MetaHorizonOSUISet [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=100mm]{./figs/提案システム/ソフトウェア/MQDH.png}
\caption[MQDH]{MQDH [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}MetaHorizonOSUISet

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=100mm]{./figs/提案システム/ソフトウェア/MetaHorizonLink.png}
\caption[MetaHorizonLink]{MetaHorizonLink [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}

[表2: 使用したソフトウェアおよびライブラリのバージョン一覧] （Unity, Meta SDK, HybridCLR, WitAI, ZXing, OpenXR等のバージョンを記載する表を挿入）

\section{システム構成}

本節では、提案システムの具体的な構成要素と、それらが連携するアーキテクチャについて詳細に述べる。提案システムは大きく分けて、(1)キュレーターが展示コンテンツを制作および出力するためのUnityプロジェクト「ARShowNode」、(2)鑑賞者が使用する閲覧用アプリケーション「ARShow」、(3)コンテンツを保持かつ配信する「静的ファイルサーバ」の三つ要素から構成される。

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=100mm]{./figs/提案システム/提案システムの全体構成図.png}
\caption[提案システムの全体構成図]{提案システムの全体構成図 [5]．}
\label{fig:tobita_config}
\end{center}
\end{figure}

[図1: 提案システムの全体構成図] （ARShowNodeでの制作、サーバへのアップロード、ARShowアプリでのQRスキャンとダウンロードの流れを示す図を挿入）

\subsection{ARShowNode}

ARShowNodeは、キュレーター（制作者）向けに提供されるUnityプロジェクトおよびツールキットである。本プロジェクトは、AR展品を「Node」という単位（Unity AssetBundle）で管理し、各Nodeには3Dモデル、音声、映像、および動的ロジック（C\#スクリプト）が含まれる。

\subsubsection{HybridCLR}

本システムにおける技術的な核心は、HybridCLRの採用にある。通常のUnity製アプリ（IL2CPPビルド）では、ビルド後にC\#スクリプトの挙動を変更することは不可能である。しかし、HybridCLRを導入することで、C\#コードをコンパイルしたDLLをアセットとして扱い、実行時にインタープリタモードでロードして実行することが可能となる。ARShowNodeでは、キュレーターが記述したスクリプトをHybridCLRによってAOT（Ahead-Of-Time）メタデータとホットアップデート用DLLに変換し、これらをAssetBundleに含めることで、アプリ本体の更新を伴わない展示ロジックの配信を実現している。

\subsubsection{制作のための Unity ツール}

本研究では、キュレーターの作業負荷を軽減するため、ARShowNodeプロジェクト内に専用のUnityエディタ拡張ツールを実装した。このツールはメニューバーからアクセス可能であり、以下の4つの機能を順次実行することで展示データの配信を行う。

DLLの複製: HybridCLRによって生成されたAOTメタデータのDLLおよびホットアップデートのDLLを、Unityプロジェクト内のAssetsディレクトリへコピーする。複数作品（Node）を同時制作する場合、各Nodeに対応したDLLを複製する。

AssetBundleのビルド: 事前に設定されたラベル（Node0, Node1...等の識別子）に基づき、各作品のリソースとDLLを含んだAssetBundleを生成する。

QRコード生成: 各AssetBundleの識別子（Node名）情報を格納したQRコード画像を自動生成する。

アップロード: 生成されたAssetBundle群を、稼働中の静的ファイルサーバへ一括アップロードする。

[図2: 実装したUnityツールのメニューと操作画面] （Unityエディタ上のドロップダウンメニューと、生成されたAssetBundle等のファイル構成を示すスクリーンショットを挿入）

\subsubsection{Node}

「Node」は、本システムにおける1つの展示作品単位であり、1つのAssetBundleに対応する。各Nodeは、展示物の実体であるPrefab、関連する設定ファイル、メディアアセット（画像、音響）、および制御用スクリプトの集合体である。本研究では、同一Unityプロジェクト内で複数のNode（Node0, Node1, Node2...）を並行して制作と管理可能な構造としている。

\subsubsection{エントリポイント (Entry.cs)}

動的にロードされたスクリプトを、実行時（Runtime）に正しくゲームオブジェクトにアタッチし機能させるため、本システムでは「Entry.cs」という規約に基づいたエントリポイントスクリプトを導入した。 通常のUnity開発ではInspector上でスクリプトをアタッチするが、別プロジェクトでビルドされたAssetBundle内のスクリプトを復元する場合、GUIDの不整合等により参照が切れる問題がある。これを回避するため、本システムではHybridCLRの推奨手法に基づき、実行時に GameObject.AddComponentメソッドを介してスクリプトを動的に付与する方式を採用した。Entry.csは各Nodeの初期化ロジックを担い、AssetBundleのロード完了後、ARShowアプリ側から明示的に呼び出されることで、Prefabのインスタンス化や依存コンポーネントのセットアップを実行する。

\subsubsection{AssetBundle}

UnityのAssetBundle機能を利用し、Nodeごとのリソースとコードをパッケージ化している。前述の通り、本システムではAssetBundle内にHybridCLR用のDLLを含める点が特徴である。これにより、3Dモデルやテクスチャだけでなく、インタラクション等の「振る舞い」も含めた完全な展示パッケージとして配信される。

\subsubsection{WitAI}

音声操作を実現するため、Meta社が提供する自然言語処理サービスWit.aiを導入した。Node内で音声認識が必要な場合、ユーザーの音声入力はMeta XR Voice SDKを通じてテキスト化され、Wit.aiサーバへ送信される。サーバ上で事前に定義されたインテント（意図）やエンティティ（Entity）の解析が行われ、その結果に基づいてUnity側の関数がトリガーされる仕組みである。本研究では、中国語による音声コマンド制御の事例を実装した。

\subsection{ARShow}

ARShowは、Meta Quest 3上で動作する鑑賞者用アプリケーションである。本アプリは、QRコードのスキャン、AssetBundleのダウンロード、および動的コンテンツの再生環境を提供するコンテナとして機能する。

\subsubsection{スキャンモード}

アプリ起動後、ユーザーはUI上の「ScanQr」ボタンを押下することでスキャンモードへ移行する。このモードでは、パススルーカメラの映像上にQRコード検出用のガイドが表示され、認識待機状態となる。

\subsubsection{QR Code 検出}

QRコードの認識には ZXing.unity ライブラリを使用し、Quest 3のカメラ映像からフレームごとの解析を行う。有効なQRコード（AssetBundleの識別子）が検出されると、スキャンモードを終了し、コンテンツのロード処理へ移行する。同一のQRコードを再スキャンした場合は、重複ロードを避けるためコンソールへ警告を表示する等の制御を行っている。

\subsubsection{アセットロード}

識別子に基づき、サーバから該当するAssetBundleをダウンロードする。ダウンロード中は、QRコードの物理位置にプログレスバー（進捗率）を空間表示し、ユーザーへのフィードバックを行う。 ダウンロード完了後、システムは以下の手順でアセットを展開する。

1、AssetBundleからHybridCLR用のAOTメタデータDLLをメモリ上に展開し、IL2CPPランタイムに登録する。

2、ホットアップデート用DLLをロードする。

3、ロードされたアセンブリ内から Entry.cs のエントリポイントメソッドをリフレクションを用いて呼び出す。 これにより、AR展品がシーン内に初期化され、インタラクションが開始される。

\subsubsection{AOT裁ちの防ぎ (AOT Stripping Prevention)}

UnityのIL2CPPビルドでは、ビルド時に使用されていないコードや型情報はファイルサイズ削減のために削除（ストリッピング）される。しかし、動的にロードされるNode側のスクリプトが、アプリ本体側で削除された型に依存している場合、実行時エラーが発生する。これを防ぐため、本システムでは link.xml ファイルを定義し、Nodeで使用する可能性のあるアセンブリや型を明示的に記述することで、ビルド時のストリッピングを回避している。これにより、ARShowNodeで開発された任意のスクリプトが、ARShowアプリ上で正しく動作することを保証している。

[図3: アセットロードとスクリプト実行の内部シーケンス図] （ダウンロード、DLLロード、Entryメソッド実行の流れを示す図を挿入）

\subsection{サーバ}

AssetBundleのホスティングには、開発用PC上で動作するASP.NET Coreベースの静的ファイルサーバを用いた。本サーバはMinimal API構成で実装されており、HTTPリクエストに応じてAssetBundleファイルを提供する単純かつ高速な仕様となっている。 ARShowアプリのメニューには、このサーバの「起動」「停止」「ディレクトリ清掃」を制御する機能も統合されており、展示運用時のサーバ管理を容易にしている。なお、開発環境（ローカルLAN）においては、サーバIPアドレスをARShowアプリ側の設定と一致させる必要がある。

\section{UI とインタラクション}

本節では、本システムにおいて実装された3つの代表的な展示作品（Node）を例に挙げ、鑑賞者が体験するユーザーインターフェース（UI）およびインタラクションの詳細について述べる。各Nodeはそれぞれ異なるメディア形式（複合UI、映像、3Dモデル）を扱っており、システムの汎用性を示している。

\subsection{Node0: 複合的なAR展示インターフェース}

Node0は、本システムの中で最も機能的に複雑な展示例であり、文化財の3Dモデル表示と解説テキスト、および音声操作を組み合わせた複合的なARコンテンツである。

\subsubsection{インターフェース構成}

本NodeのUIは、Meta Horizon OS UI Setをベースに構築されており、Meta Questの標準的なシステムUIと親和性の高いデザインを採用している。画面構成は主に「3Dモデル表示領域」と「操作用テキストキャンバス」の2つのモジュールから成る。テキストキャンバスは、機能に応じて以下の3つのセクションに区分されている。

スクリーンリーダー制御: 解説音声の「再生（Play）」「一時停止（Pause）」「停止（Stop）」を行うボタン群。

情報表示と設定: 文化財の解説テキストを表示するエリアおよび言語選択ドロップダウンメニュー。言語切り替えにより、テキストと読み上げ音声が即座に変更される。

音声コマンド制御: 「Speak」ボタンと認識結果を表示するテキストボックス。

\subsubsection{インタラクション}

鑑賞者は、ハンドトラッキング機能を用いた以下のように直感的な操作が可能である。

1、タッチ操作（Poke）: 仮想ボタンを指先で直接押すことで、再生制御やモード切替を行う。

2、遠隔操作（Ray）: 手から発せられるレイ（光線）を用いて、離れた位置にあるUI要素を選択・操作する。

3、把持操作（Grab）: UIパネルや3Dモデルを「掴む」ジェスチャにより、鑑賞しやすい位置や角度へ自由に移動させることができる。

これらのインタラクションを実現するため、技術的には CanvasModuleEvent システムを利用している。通常、このイベントシステムはUnityシーン内に常駐する必要があるが、本システムでは動的にロードされるNode側（ARShowNode）で定義されたイベント設定を、実行時に本体アプリ（ARShow）のシーンへ正しく引き継ぐ仕組みを実装することで、スムーズな操作性を確保している。

\subsubsection{音声コマンド制御}

「Speak」ボタンを押下すると音声認識モードへ移行し、Wit.aiを介したボイスコマンドによる操作が可能となる。例えば、所定のキーワードを発話することで、ボタン操作なしに解説の再生や言語変更を行うことができる。認識された発話内容はUI上にテキストとしてフィードバックされ、確実な入力を支援する。

[図4: Node0のインターフェース構成（第一人称視点）] （解説パネル、操作ボタン、3Dモデルの配置を示したARビューのスクリーンショットを挿入）

\subsection{Node1: 映像コンテンツの空間配置}

Node1は、映像メディアをAR空間内に配置する展示例である。Unityのプリミティブ形状であるQuad（板ポリゴン）にVideo Playerコンポーネントを付加し、独自の録画映像と音声を再生する構成となっている。本NodeにもGrabインタラクションが付与されており、鑑賞者は空中に浮かぶスクリーンを手に取り、壁面に配置したり、目の前に引き寄せて細部を確認したりといった、物理的なスクリーンと同様の取り回しが可能である。これは、動画解説パネルやデジタルサイネージとしての利用を想定した実装である。

[図5: Node1 映像コンテンツの再生と把持操作の様子] （空間に浮かぶ映像スクリーンを手で移動させている様子を示す図を挿入）

\subsection{Node2: 3Dモデル（文化財）の展示}

Node2は、静的な3Dオブジェクトの展示に特化した最小構成の例である。ここでは、Sketchfabより取得した青銅器の3Dモデル（glTF形式）をPrefab化し、AssetBundleとして配信している。Node1同様、Grabインタラクションが設定されており、鑑賞者は貴重な文化財モデルを仮想的に手に取り、あらゆる角度から詳細に観察することができる。このNodeは、複雑なスクリプトを含まない純粋なアセットデータも、本システムを通じて問題なく配信や操作可能であることを実証している。

\section{ワークフロー}

本節では、本システムを用いたAR展示の制作から鑑賞に至るまでの具体的なワークフローについて、制作サイド（キュレーター）と鑑賞サイド（閲覧者）の双方の視点から述べる。

\subsection{制作サイド（キュレーター）}

キュレーター側の作業は、Unityプロジェクト「ARShowNode」を用いて行われる。

\subsubsection{ARShowNode プロジェクトの配置}

まず、キュレーターは提供される「ARShowNode」プロジェクトを開発環境に展開する。このプロジェクトには、Meta XR All-in-One SDK、HybridCLR、および本研究で開発した専用ツールキット等の依存ライブラリが事前設定されている。キュレーターは、Unityエディタ上でコンパイルエラーがない状態を確認し、自身のコンテンツ（Prefabやスクリプト）の制作を開始する。

\subsubsection{Assembly のビルド}

作品のロジック（C\#スクリプト）をホットアップデート可能な形式に変換するため、HybridCLRのビルド機能を実行する。まず、HybridCLRメニューから Install を実行し、環境を初期化する。次にCompileDllコマンドを実行し、ターゲットプラットフォーム（Android/Quest）向けのDLL（AOTメタデータおよびホットアップデート用アセンブリ）を出力する。そしてGenerateコマンドを実行し、ブリッジコード等を生成する。

\subsubsection{AssetBundleの事前準備}

DLLのビルド完了後、上述の本研究が提供したUnityツール（ARShowTool）を用いて、以下の手順で配信準備を行う。

DLLの配置: ツールメニューの「Move DLLs」を実行し、生成されたDLLファイルをUnityプロジェクトのAssetsフォルダへ複製する。

バンドル設定: 各作品のリソース（Prefab, DLL等）に対し、一意のAssetBundleラベル（例: node0）を付与する。

ビルド実行: ツールメニューの「Build AssetBundles」を実行する。これにより、ラベル付けされたリソースが一つのAssetBundleファイルとしてパッケージ化される。

QRコード生成: ツールメニューの「Generate QR」を実行し、各AssetBundleに対応するQRコード画像を生成する。

\subsubsection{サーバへのアップロード}

最後に、ツールメニューの「Upload to Server」を実行する。これにより、生成された全てのAssetBundleファイルが、LAN内で稼働している静的ファイルサーバの公開ディレクトリへ自動的に転送される。以上で、展示コンテンツの公開作業は完了である。

[図6: 制作サイドのワークフローとUnityツールの操作手順] （DLLビルドからサーバアップロードまでの各ステップを示すフローチャートまたはスクリーンショットを挿入）

\subsection{鑑賞サイド（鑑賞者）}

鑑賞者は、HMD（Meta Quest 3）を装着し、以下の手順で展示を体験する。

\subsubsection{ARShow AR APP のインストール}

事前に、Meta Quest Developer Hub (MQDH) 等を経由して、閲覧用アプリ「ARShow」をデバイスにインストールする（将来的なストア配布も想定される）。

\subsubsection{スキャンモードによる開始}

アプリを起動すると、空間上に「ScanQr」ボタンが表示される。これをクリックすると、パススルーカメラを用いたQRコードスキャンモードに移行する。鑑賞者が展示会場に掲示されたQRコードに視線を向けると、システムは自動的にコードを認識して解析する。

\subsubsection{プログラムの実行フロー}

QRコードの認識後、システムは以下のフローを自動的に実行する。

1、ダウンロード: 解析されたIDに基づき、サーバから対応するAssetBundleをダウンロードする。進捗状況は空間上のプログレスバーで可視化される。

2、アセンブリロード: ダウンロード完了後、AssetBundle内のAOTメタデータDLLとホットアップデートDLLをメモリに展開する。

3、初期化 (Entry Point): ロードされたアセンブリ内の Entry.cs を特定し、その初期化メソッドを実行する。この段階で、展示作品のPrefabがシーン内に生成（Instantiate）され、必要なコンポーネントが動的にアタッチされる。

4、登録と管理: 生成された作品はIDと共に内部辞書に登録される。スキャンモードは終了し、鑑賞者は作品とのインタラクションが可能となる。なお、既にロード済みのQRコードを再スキャンした場合は、重複ロードを防ぐためコンソールに警告が表示され、スキャンモードが解除される仕様となっている。

[図7: 鑑賞サイドのプログラム実行フロー図] （QRスキャン判定、DL処理、Assembly Load、Entry実行、完了までの処理フロー図を挿入）
